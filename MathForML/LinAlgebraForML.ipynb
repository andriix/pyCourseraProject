{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[ 1  4  7 10 13 16 19]\n",
      "[  0  25  50  75 100]\n",
      "['Oss, white belt']\n",
      "<U15\n",
      "[1 1 1 1 1]\n",
      "[0.12131736 0.76537744 0.21283142 0.81836389]\n",
      "\n",
      "[[11 12 13]\n",
      " [21 22 23]]\n",
      "[[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]]\n",
      "dimension: 2, shape: (2, 5), size: 10\n",
      "[ 4 10 18]\n",
      "a1:\n",
      "[[1 1]\n",
      " [2 2]]\n",
      "a2:\n",
      "[[3 3]\n",
      " [4 4]]\n",
      "horiz:\n",
      "[[1 1 3 3]\n",
      " [2 2 4 4]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Introduction to Python Matrices and NumPy\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Basics\n",
    "arr1 = np.arange(5)\n",
    "print(arr1)\n",
    "\n",
    "arr2 = np.arange(1,20,3)\n",
    "print(arr2)\n",
    "\n",
    "lin_spaced_arr = np.linspace(0,100,5, dtype = int)\n",
    "print(lin_spaced_arr)\n",
    "\n",
    "char_arr = np.array(['Oss, white belt'])\n",
    "print(char_arr)\n",
    "print(char_arr.dtype)\n",
    "\n",
    "ones = np.ones(5, dtype = int)\n",
    "print(ones)\n",
    "\n",
    "rand_arr = np.random.rand(4)\n",
    "print(rand_arr)\n",
    "print()\n",
    "\n",
    "#Multidimensional Arrays\n",
    "two_D_arr = np.array([[11,12,13],[21,22,23]])\n",
    "print(two_D_arr)\n",
    "\n",
    "one_D_arr = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "multi_D_arr = np.reshape(one_D_arr, (2,5))\n",
    "print(multi_D_arr)\n",
    "\n",
    "print(\"dimension: \" + str(multi_D_arr.ndim) + \", shape: \" + str(multi_D_arr.shape) + \", size: \" + str(multi_D_arr.size))\n",
    "\n",
    "multip_arr = np.array([1,2,3]) * np.array([4,5,6])\n",
    "print (multip_arr)\n",
    "\n",
    "a1 = np.array([[1,1],\n",
    "               [2,2]])\n",
    "a2 = np.array([[3,3],\n",
    "               [4,4]])\n",
    "print(f'a1:\\n{a1}')\n",
    "print(f'a2:\\n{a2}')\n",
    "\n",
    "vert_stack = np.hstack((a1,a2))\n",
    "print(f\"horiz:\\n{vert_stack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solving Linear Systems with 2 variables\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# solve a system using matrices\n",
    "A = np.array([\n",
    "    [-1, 3],\n",
    "    [3, 2]\n",
    "])\n",
    "b = np.array([7,1])\n",
    "x = np.linalg.solve(A,b)\n",
    "print(f\"Solution: {x}\")\n",
    "\n",
    "#evaluate determinant\n",
    "detA = np.linalg.det(A)\n",
    "print(f\"Determinant of A: {detA}\")\n",
    "\n",
    "#solve a system using Elimination Method\n",
    "A_system = np.hstack((A,b.reshape((2,1))))\n",
    "print(f\"A_system:\\n{A_system}\")\n",
    "A_syst_res = A_system.copy()\n",
    "A_syst_res[1] = 3 * A_syst_res[0] + A_syst_res[1]\n",
    "print(f\"A_system_res:\\n{A_syst_res}\")\n",
    "A_syst_res[1]= 1/11 * A_syst_res[1]\n",
    "print(f\"A_system_res:\\n{A_syst_res}\")\n",
    "\n",
    "#Graphical Representation of the Solution\n",
    "def plot_lines(matr):\n",
    "    x_1 = np.linspace(-10,10,100)\n",
    "    x_2_line_1 = (matr[0,2] - matr[0,0] * x_1) / matr[0,1]\n",
    "    x_2_line_2 = (matr[1,2] - matr[1,0] * x_1) / matr[1,1]\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.plot(x_1, x_2_line_1, '-', linewidth=2, color='#0075ff',\n",
    "            label=f'$x_2={-matr[0,0] / matr[0,1]:.2f}x_1 + {matr[0,2] / matr[0,1]:.2f}$')\n",
    "    ax.plot(x_1, x_2_line_2, '-', linewidth=2, color='#ff7300',\n",
    "            label=f'$x_2={-matr[1,0] / matr[1,1]:.2f}x_1 + {matr[1,2] / matr[1,1]:.2f}$')\n",
    "\n",
    "    A = matr[:, 0:-1]\n",
    "    b = matr[:, -1::].flatten()\n",
    "    d = np.linalg.det(A)\n",
    "\n",
    "    if d != 0:\n",
    "        solution = np.linalg.solve(A,b)\n",
    "        ax.plot(solution[0], solution[1], '-o', mfc='none',\n",
    "                markersize=10, markeredgecolor='#ff0000', markeredgewidth=2)\n",
    "        ax.text(solution[0]-0.25, solution[1]+0.75, f'$(${solution[0]:.0f}$,{solution[1]:.0f})$', fontsize=14)\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    ax.set_xticks(np.arange(-10, 10))\n",
    "    ax.set_yticks(np.arange(-10, 10))\n",
    "\n",
    "    plt.xlabel('$x_1$', size=14)\n",
    "    plt.ylabel('$x_2$', size=14)\n",
    "    plt.legend(loc='upper right', fontsize=14)\n",
    "    plt.axis([-10, 10, -10, 10])\n",
    "\n",
    "    plt.grid()\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_lines(A_system)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solving Linear Systems with 3 variables\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [4, -3, 1],\n",
    "    [2, 1, 3],\n",
    "    [-1, 2, -5]\n",
    "])\n",
    "b = np.array([-10, 0, 17])\n",
    "\n",
    "x = np.linalg.solve(A,b)\n",
    "print(f\"solution for the matrix with det {np.linalg.det(A):.2f}: {x}\")\n",
    "\n",
    "AA = np.hstack((A,b.reshape((3,1))))\n",
    "print(f\"matrix AA: \\n{AA}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Row echelon form\n",
    "\"\"\"\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [3, 4, 7],\n",
    "    [6, 5, 9]\n",
    "])\n",
    "b = np.array([-10, 0, 17])\n",
    "M = sp.Matrix(np.hstack((A,b.reshape((3,1)))))\n",
    "print(f\"Matrix: \\n{np.array(M).astype(np.float64)}\")\n",
    "# np.array(M).astype(np.float64).\n",
    "\n",
    "M_row_echelon= M.echelon_form()\n",
    "print(f\"row echelon form: \\n{np.array(M_row_echelon).astype(np.float64)}\")\n",
    "M_reduced_echelon = M.rref()[0]\n",
    "print(f\"reduced row echelon form: \\n{np.array(M_reduced_echelon).astype(np.float64)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lab: Vector operations\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def plot_vectors(list_v, list_label, list_color):\n",
    "    _, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.tick_params(axis='x', labelsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    ax.set_xticks(np.arange(-10, 10))\n",
    "    ax.set_yticks(np.arange(-10, 10))\n",
    "\n",
    "\n",
    "    plt.axis([-10, 10, -10, 10])\n",
    "    for i, v in enumerate(list_v):\n",
    "        sgn = 0.4 * np.array([[1] if i==0 else [i] for i in np.sign(v)])\n",
    "        plt.quiver(v[0], v[1], color=list_color[i], angles='xy', scale_units='xy', scale=1)\n",
    "        ax.text(v[0]-0.2+sgn[0], v[1]-0.2+sgn[1], list_label[i], fontsize=14, color=list_color[i])\n",
    "\n",
    "    plt.grid()\n",
    "    plt.gca().set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "v = np.array([[1],[3]])\n",
    "# Scalar multiplication\n",
    "#plot_vectors([v, 2*v, -2*v], [f\"$v$\", f\"$2v$\", f\"$-2v$\"], [\"black\", \"green\", \"blue\"])\n",
    "\n",
    "# Sum of vectors\n",
    "v = np.array([[1],[3]])\n",
    "w = np.array([[4],[-1]])\n",
    "#plot_vectors([v, w, v + w], [f\"$v$\", f\"$w$\", f\"$v + w$\"], [\"black\", \"black\", \"red\"])\n",
    "#plot_vectors([v, w, np.add(v, w)], [f\"$v$\", f\"$w$\", f\"$v + w$\"], [\"black\", \"black\", \"red\"])\n",
    "\n",
    "# Norm of a Vector\n",
    "print(\"Norm of a vector v is\", np.linalg.norm(v))\n",
    "\n",
    "# Dot Product\n",
    "x = [1, -2, -5]\n",
    "y = [4, 3, -1]\n",
    "\n",
    "def dot(x, y):\n",
    "    s = 0\n",
    "    for xi, yi in zip(x, y):\n",
    "        s += xi * yi\n",
    "    return s\n",
    "\n",
    "print(f\"The dot product of {x}  and {y} is {dot(x, y)}\")\n",
    "print(\"np.dot(x,y) function returns dot product of x and y:\", np.dot(x, y))\n",
    "print(\"This line output is a dot product of x and y: \", np.array(x) @ np.array(y))\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Speed of Calculations in Vectorized Form\n",
    "a = np.random.rand(1000001)\n",
    "b = np.random.rand(1000001)\n",
    "\n",
    "tic = time.time()\n",
    "c = dot(a,b)\n",
    "toc = time.time()\n",
    "print(f\"\\nDot product: {c}\")\n",
    "print (\"Time for the loop version:\" + str(1000*(toc-tic)) + \" ms\")\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(b,a)\n",
    "toc = time.time()\n",
    "print(\"Dot product: \", c)\n",
    "print (\"Time for the vectorized version, np.dot() function: \" + str(1000*(toc-tic)) + \" ms\")\n",
    "\n",
    "i = np.array([1, 0, 0])\n",
    "j = np.array([0, 1, 0])\n",
    "print(\"The dot product of i and j is\", dot(i, j))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A (3 by 3):\n",
      " [[4 9 9]\n",
      " [9 1 6]\n",
      " [9 2 3]]\n",
      "Matrix B (3 by 2):\n",
      " [[2 2]\n",
      " [5 7]\n",
      " [4 4]]\n",
      "AB with matmul: \n",
      " [[ 89 107]\n",
      " [ 47  49]\n",
      " [ 40  44]]\n",
      "AB with Dot Product: \n",
      " [[ 89 107]\n",
      " [ 47  49]\n",
      " [ 40  44]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lab: Matrix Multiplication\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[4, 9, 9], [9, 1, 6], [9, 2, 3]])\n",
    "print(\"Matrix A (3 by 3):\\n\", A)\n",
    "\n",
    "B = np.array([[2, 2], [5, 7], [4, 4]])\n",
    "print(\"Matrix B (3 by 2):\\n\", B)\n",
    "\n",
    "AB = np.matmul (A,B)\n",
    "AB_dotP = np.dot(A, B) # broadcasting\n",
    "print(f\"AB with matmul: \\n {AB}\")\n",
    "print(f\"AB with Dot Product: \\n {AB_dotP}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector:\n",
      " [[3]\n",
      " [5]] \n",
      "\n",
      " Result of the transformation:\n",
      " [[  9.]\n",
      " [  0.]\n",
      " [-10.]]\n",
      "Transformation matrix:\n",
      " [[ 3  0]\n",
      " [ 0  0]\n",
      " [ 0 -2]] \n",
      "\n",
      "Original vector:\n",
      " [[3]\n",
      " [5]] \n",
      "\n",
      " Result of the transformation:\n",
      " [[  9]\n",
      " [  0]\n",
      " [-10]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Linear Transformations\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def T(v):\n",
    "    w = np.zeros((3,1))\n",
    "    w[0,0] = 3*v[0,0]\n",
    "    w[2,0] = -2*v[1,0]\n",
    "\n",
    "    return w\n",
    "\n",
    "v = np.array([[3], [5]])\n",
    "w = T(v)\n",
    "print(\"Original vector:\\n\", v, \"\\n\\n Result of the transformation:\\n\", w)\n",
    "\n",
    "def L(v):\n",
    "    A = np.array([[3,0], [0,0], [0,-2]])\n",
    "    print(\"Transformation matrix:\\n\", A, \"\\n\")\n",
    "    w = A @ v\n",
    "\n",
    "    return w\n",
    "\n",
    "v = np.array([[3], [5]])\n",
    "w = L(v)\n",
    "\n",
    "print(\"Original vector:\\n\", v, \"\\n\\n Result of the transformation:\\n\", w)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset X:\n",
      "[[ 0.3190391  -1.07296862  0.86540763 -0.17242821  1.14472371  0.50249434\n",
      "  -2.3015387  -0.68372786 -0.38405435 -0.87785842 -2.06014071 -1.10061918\n",
      "  -1.09989127  1.13376944  1.74481176 -0.12289023 -0.93576943  1.62434536\n",
      "   1.46210794  0.90159072 -0.7612069   0.53035547 -0.52817175 -0.26788808\n",
      "   0.58281521  0.04221375  0.90085595 -0.24937038 -0.61175641 -0.3224172 ]]\n",
      "Training dataset Y\n",
      "[[ -3.01854669 -65.65047675  26.96755728   8.70562603  57.94332628\n",
      "   -0.69293498 -78.66594473 -12.73881492 -13.26721663 -24.80488085\n",
      "  -74.24484385 -39.99533724 -22.70174437  73.46766345  55.7257405\n",
      "   23.80417646 -13.45481508  25.57952246  75.91238321  50.91155323\n",
      "  -43.7191551   -1.7025559  -16.44931235 -33.54041234  20.4505961\n",
      "   18.35949302  37.69029586  -1.04801683  -4.47915933 -20.89431647]]\n",
      "The shape of X: (1, 30)\n",
      "The shape of Y: (1, 30)\n",
      "I have m = 30 training examples!\n",
      "The size of the input layer is: n_x = 1\n",
      "The size of the output layer is: n_y = 1\n",
      "W = [[0.01788628]]\n",
      "b = [[0.]]\n",
      "[[ 0.00570642 -0.01919142  0.01547893 -0.0030841   0.02047485  0.00898776\n",
      "  -0.04116598 -0.01222935 -0.00686931 -0.01570163 -0.03684826 -0.01968599\n",
      "  -0.01967297  0.02027892  0.0312082  -0.00219805 -0.01673744  0.0290535\n",
      "   0.02615168  0.01612611 -0.01361516  0.00948609 -0.00944703 -0.00479152\n",
      "   0.0104244   0.00075505  0.01611297 -0.00446031 -0.01094205 -0.00576685]]\n",
      "cost = 790.2189412622606\n",
      "W = [[43.63332681]]\n",
      "b = [[0.17937262]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYB0lEQVR4nO3df5AkZ13H8ffncgYcfpjEuySXHzuTlBcgiSDcGiOUGvNDYkzlYpWUZy3xStAtEBUoLUycKlFxq1Ao8BdIbYHUUbuSigrkiiKQuxO0qDKEDSSQI8Q7k91NvDPZQInKlodhv/4xvWHvMr07uzvdT/fM51U1NTPdPT3f6dub7zzP0/19FBGYmZl1syV1AGZmVl1OEmZmlstJwszMcjlJmJlZLicJMzPLtTV1AP20bdu2aLVaqcMwM6uV++6776mI2N5t3UAliVarxczMTOowzMxqRdJc3rpKdDdJequkw5IelPRRSc+VdJakA5KOZPdnpo7TzGzYJE8Sks4HfgsYjYjLgdOAPcCtwKGI2Akcyp6bmVmJkieJzFbg+yVtBRrAMWA3sC9bvw+4OU1oZmbDK3mSiIh/B94NzAPHgW9FxN3AORFxPNvmOHB2t9dLGpc0I2lmYWGhrLDNzIZC8iSRjTXsBi4CzgOeJ+m1vb4+IiYjYjQiRrdv7zo4b2ZmG5Q8SQDXAo9GxEJE/B/wMeCVwBOSdgBk908mjNHMbNOmp6dptVps2bKFVqvF9PR06pDWVIUkMQ9cKakhScA1wEPAfmBvts1e4M5E8ZmZbdr09DTj4+PMzc0REczNzTE+Pl75RKEqlAqX9IfALwJPA18GfhV4PnAHMEInkbwmIr652n5GR0fD10mYWRW1Wi3m5p59OUKz2WR2drb8gFaQdF9EjHZbV4WWBBHx9oh4cURcHhG3RMSJiPhGRFwTETuz+1UThJnZZhTdFTQ/P7+u5VVRiSRhZpZSGV1BIyMj61peFU4SZjb02u02i4uLJy1bXFyk3W737T0mJiZoNBonLWs0GkxMTPTtPYrgJGFmQ6+MrqCxsTEmJydpNptIotlsMjk5ydjYWN/eowiVGLjuFw9cm9lGVHlQuQyVH7g2M0uprl1BZXCSMLOhV9euoDK4u8nMbMi5u8nMzDbEScLMzHI5SZiZWS4nCTMzy+UkYWZmuZwkzMwsl5OEmZnlcpIwM7NcThJmZparEklC0hmS/l7S1yU9JOnHJZ0l6YCkI9n9manjNDMbNpVIEsCfA5+OiBcDL6Mzx/WtwKGI2Akcyp6bmVmJkicJSS8EfhL4EEBEfCci/hPYDezLNtsH3JwiPjOzYZY8SQAXAwvAhyV9WdIHJT0POCcijgNk92enDNLMBl/R81zXURWSxFbgFcBfR8TLgW+zjq4lSeOSZiTNLCwsFBWjmQ24Mua5rqPkpcIlnQvcExGt7PlP0EkSPwRcFRHHJe0APhcRL1ptXy4VbmYbNcyz01W6VHhE/AfwmKTlBHAN8DVgP7A3W7YXuDNBeGY2JMqY57oIRXeRbe3r3jbuN4FpSacDjwC/QieB3SHp9cA88JqE8ZnZgBsZGenakhgZGUkQTW+Wu8gWFxcBnukiA/o2q17y7qZ+cneTmW3UqV+40JnnusrTmPari6zS3U1mZlVQx3muy+gic0vCzKym3JIwM7NcExMTNBqNk5Y1Gg0mJib69h5OEmZWa8N8AVwZXWTubjKz2qrjYHMVubvJzAZSu90+KUEALC4u0m63E0U0eJwkzKy26noBXJ04SZhZbeVd6FblC+DqxknCzGqrjLN7hp2ThJnVVh0vgKsbn91kZjbkfHaTmZltiJOEmZnlcpIwM7NcThJmZpbLScLMzHI5SZiZWa7KJAlJp0n6sqRPZs/PknRA0pHs/szUMZqZDZvKJAngzcBDK57fChyKiJ3Aoey5mZmVqBJJQtIFwM8BH1yxeDewL3u8D7i55LDMzIZeJZIE8GfA24ClFcvOiYjjANn92d1eKGlc0oykmYWFhcIDNbNqGeZJh8qQPElIuhF4MiLu28jrI2IyIkYjYnT79u19js7Mqmx50qG5uTkigrm5OcbHx50o+ih5kgBeBdwkaRa4Hbha0hTwhKQdANn9k+lCNLMq8qRDxUueJCLitoi4ICJawB7gHyPitcB+YG+22V7gzkQhmllFedKh4iVPEqt4J3CdpCPAddlzM7NneNKh4lUqSUTE5yLixuzxNyLimojYmd1/M3V8ZlYtnnSoeJVKEmZm6+FJh4rnSYfMzIacJx0yM7MNcZIwM7NcThJmZpbLScLMzHI5SZiZWS4nCTMzy+UkYWa15Oqv5diaOgAzs/Varv66XNxvufor4Avp+swtCTOrnWGp/lqF1pJbEmZWO8NQ/bUqrSW3JMwqpAq/HOtgGKq/VqW15CRhVhGeZa13w1D9tSqtJScJs4qoyi/HOhiG6q9VaS25CqxZRWzZsoVu/x8lsbS0lCAiS+nUMQnotJaKSIauAmtWA1X55VgEj7WsX2VaSxGR9AZcCHwWeAg4DLw5W34WcAA4kt2fuda+du3aFWZ1NTU1FY1GI4Bnbo1GI6amplKHtimD+rkGCTATOd+rVWhJPA38dkS8BLgSeJOkS4FbgUMRsRM4lD03G1iV+eXYZx5rqbfkSSIijkfEl7LH/02nRXE+sBvYl222D7g5SYBmJRobG2N2dpalpSVmZ2d7ShBV78qpylk6tjHJk8RKklrAy4EvAOdExHHoJBLg7JzXjEuakTSzsLBQWqxmVVCH02YHeaxlGFQmSUh6PvAPwFsi4r96fV1ETEbEaESMbt++vbgAzSqoDl05w3BNwyCrRJKQ9H10EsR0RHwsW/yEpB3Z+h3Ak6niM6uqOnTlDOpYy7BIniQkCfgQ8FBEvGfFqv3A3uzxXuDOsmMzq7q6dOVsZKzFqiF5kgBeBdwCXC3p/ux2A/BO4DpJR4DrsudmtoK7cqxoyavARsTnAeWsvqbMWMzqZvkXebvdZn5+npGRESYmJvxL3frGZTnMzIacy3KYmdmGOEmYmVkuJwkzM8vlJGFmZrmcJMwSq3rtJRtuyU+BNRtmVZns3iyPWxJmCdWh9pINNycJs4TqUHvJhpuThFlCdam9ZMPLScIsIddesqpzkjBLyGW0repcu8nMbMi5dpOZmW2Ik4SZmeVykjAzs1yVTxKSrpf0sKSjkm5NHY+Z2TCpdJKQdBrwPuBngUuBX5J0adqozKwb16AaTJVOEsAVwNGIeCQivgPcDuxOHJPZhgzyl+hyDaq5uTkigrm5OW655RYkDdxnHTZVL/B3PvDYiuePAz+2cgNJ48A4+CpVq65BL+TXrQbV8un1g/ZZh82aLQlJByW9rIxgur19l2UnXdgREZMRMRoRo9u3by8pLLP1qVshv/W2etaqNVXlz2qr66W76W3AeyV9WNKOogM6xePAhSueXwAcKzkGs02rUyG/bl1H4+PjqyaKXlrxVfystrY1k0REfCkirgY+CXxa0tslfX/xoQHwRWCnpIsknQ7sAfaX9N42BMoaJ6hTIb+NtHq61aA6VRU/q/UgIta80en2uRx4A/AUnV/4t/Ty2s3egBuAfwX+DWivtu2uXbvCrFdTU1PRaDSCThdmANFoNGJqaqrW77VZkk6Kc/kmadXXTU1NRbPZfGbbOnxW6wBmIu87OG9FfO9L+vN0ungOAO8AbgR+CPhLYHKt15d5c5Kw9Vj+Qjv11mw2C3m/5S9RSdFsNiv7pdmP41KXz2odqyWJNQv8SbocOBxdNpT0UES8pNdWS9Fc4M/WY8uWLXT7+5fE0tJSgoiq4dQzsaBTvtzVaQfXpgr8RcSD3RJE5uc2FZlZQnUaJyiTy5fbSpu6mC4iHulXIGZl84Q/+cbGxpidnWVpaYnZ2VkniCFW9SuuzQrjX8xma/OkQ2ZmQ86TDpmZ2YY4SZiZWS4nCTMzy+UkYUOhyPIbg1wC3MxJwiqrX1++GylYV4V9m1WBz26ySurnVb+tVou5ublnLW82m8zOzm4qziL3bVaW1c5ucpKwSurnl2+R5Tdc2sMGgU+Btdrp5/wLGym/0WtXl0t72KBzkrBK6ueX73rLb6xnnMGlPWzg5ZWHrePNpcIHR7/nX1hP6er1lsp2WWyrOzZTKrxOPCYxWKanp2m328zPzzMyMsLExEQpdZU8zmDDxgPXZuvgM5Zs2FR24FrSuyR9XdJXJH1c0hkr1t0m6aikhyW9OmGYNmQ8zmD2PakHrg8Al0fES+nMY30bgKRLgT3AZcD1wPslnZYsShsqmy0h7iuwbZBsTfnmEXH3iqf3AL+QPd4N3B4RJ4BHJR0FrgD+peQQbUiNjY1taPzj1IsAl8+MWt6nWd2kbkms9Drgruzx+cBjK9Y9ni17FknjkmYkzSwsLBQcom3GMPzCbrfbJ10lDrC4uEi73U4UkdnmFN6SkHQQOLfLqnZE3Jlt0waeBpa/NdRl+64j7BExCUxCZ+B60wFbIYblF3Y/LwI0q4LCWxIRcW1EXN7ltpwg9gI3AmPxvVOtHgcuXLGbC4BjRcdqxRmWX9i+AtsGTeqzm64Hfhe4KSJWfoPsB/ZIeo6ki4CdwL0pYrT+6Ncv7Kp3WfnMKBs0qcck/gp4AXBA0v2SPgAQEYeBO4CvAZ8G3hQR300Xpm1WP35h16Es92bPjDKrGl9MZ6XoR+lvX+RmVozKXkxnw6Mfv7A9KGxWPrckrDbckjArhlsSNhA8KGxWPicJqw0PCpuVz91NZmZDzt1NZma2IU4SZmaWy0nCzMxyOUmYlaDq5UTM8iSdT8JsGAxLBVwbTG5JmBVsWCrg2mBykjArmMuJWJ05SZgVzHNMWJ05SZgVzOVErM6cJMwK5nIiVmcuy2FmNuQqX5ZD0u9ICknbViy7TdJRSQ9LenXK+Kw/fK2AWf0kv05C0oXAdcD8imWXAnuAy4DzgIOSLvEUpvXlawXM6qkKLYn3Am8DVvZ77QZuj4gTEfEocBS4IkVw1h++VsCsnpImCUk3Af8eEQ+csup84LEVzx/PlnXbx7ikGUkzCwsLBUVqm+VrBczqqfDuJkkHgXO7rGoDvwf8TLeXdVnWdYQ9IiaBSegMXG8wTCvYyMhI16lHfa2AWbUV3pKIiGsj4vJTb8AjwEXAA5JmgQuAL0k6l07L4cIVu7kAOFZ0rFacsq4V8OC4WZ9FRCVuwCywLXt8GfAA8Bw6ieQR4LS19rFr166w6pqamopmsxmSotlsxtTUVN/332g0gk6rM4BoNBp9fx+zQQPMRM73amWuk8haE6MR8VT2vA28DngaeEtE3LXWPnydxHBrtVpdu7SazSazs7PlB2RWE6tdJ1GZJNEPThLDbcuWLXT7e5bE0tJSgojM6qHyF9OZ9YML6Zn1n5OEDQwX0jPrPycJGxgupGfWfx6TMDMbch6TMDOzDXGSMDOzXE4SZmaWy0nCzMxyOUmYmVkuJwkzM8vlJGFmZrmcJMzMLJeThJmZ5XKSMDOzXE4SZmaWy0nCzMxyOUmYmVmu5ElC0m9KeljSYUl/umL5bZKOZutenTJGM7NhtTXlm0v6aWA38NKIOCHp7Gz5pcAe4DLgPOCgpEsi4rvpojUzGz6pWxJvBN4ZEScAIuLJbPlu4PaIOBERjwJHgSsSxWhmNrRSJ4lLgJ+Q9AVJ/yTpR7Pl5wOPrdju8WzZs0galzQjaWZhYaHgcM3Mhkvh3U2SDgLndlnVzt7/TOBK4EeBOyRdDKjL9l2n0IuISWASOjPT9SNmMzPrKDxJRMS1eeskvRH4WHTmUL1X0hKwjU7L4cIVm14AHCs0UDMze5bU3U2fAK4GkHQJcDrwFLAf2CPpOZIuAnYC96YK0sxsWKVOEn8DXCzpQeB2YG90HAbuAL4GfBp4k89sGhzT09O0Wi22bNlCq9Vieno6dUhmliPpKbAR8R3gtTnrJoCJciOyok1PTzM+Ps7i4iIAc3NzjI+PAzA2NpYyNDPrInVLwoZMu91+JkEsW1xcpN1uJ4rIzFbjJGGlmp+fX9dyM0vLScJKNTIysq7lZpaWk4SVamJigkajcdKyRqPBxISHn8yqyEnCSjU2Nsbk5CTNZhNJNJtNJicnPWhtVlHqXMc2GEZHR2NmZiZ1GGZmtSLpvogY7bbOLQkzM8vlJGFmZrmcJMzMLJeTRB+53ISZDZqkZTkGictNmNkgckuiT1xuwswGkZNEn7jchJkNIieJPnG5CTMbRE4SfeJyE2Y2iJwk6M9ZSS43YWaDKGlZDkk/AnwAeC7wNPDrEXFvtu424PXAd4HfiojPrLW/jZTlOPWsJOi0APwFb2bDYrWyHKmTxN3AeyPiLkk3AG+LiKskXQp8FLgCOA84CFyy1hSmG0kSrVaLubm5Zy1vNpvMzs6ua19mZnVU5dpNAbwwe/wDwLHs8W7g9og4ERGPAkfpJIy+81lJZmb5Ul9M9xbgM5LeTSdhvTJbfj5wz4rtHs+W9d3IyEjXloTPSjIzK6ElIemgpAe73HYDbwTeGhEXAm8FPrT8si676tovJmlc0oykmYWFhXXH57OSzMzyFd6SiIhr89ZJ+gjw5uzp3wEfzB4/Dly4YtML+F5X1Kn7nwQmoTMmsd74lgen2+028/PzjIyMMDEx4UFrMzPSdzcdA34K+BxwNXAkW74f+FtJ76EzcL0TuLeoIMbGxpwUzMy6SJ0kfg34c0lbgf8FxgEi4rCkO4Cv0Tk19k1rndlkZmb9lzRJRMTngV056yYADwyYmSWU+hRYMzOrMCcJMzPL5SRhZma5kpbl6DdJC8C3gadSx3KKbVQvJqhmXFWMCRzXelQxJqhmXFWJqRkR27utGKgkASBpJq8GSSpVjAmqGVcVYwLHtR5VjAmqGVcVYzqVu5vMzCyXk4SZmeUaxCQxmTqALqoYE1QzrirGBI5rPaoYE1QzrirGdJKBG5MwM7P+GcSWhJmZ9YmThJmZ5ap9kpD0Lklfl/QVSR+XdEbOdrOSvirpfknrm+O0uJiul/SwpKOSbi0ypuz9XiPpsKQlSbmn3ZV8rHqNqexjdZakA5KOZPdn5mxX+LFa67Or4y+y9V+R9Ioi4thAXFdJ+lZ2bO6X9PslxPQ3kp6U9GDO+lTHaq24Sj9WPYuIWt+AnwG2Zo//BPiTnO1mgW1ViQk4Dfg34GLgdOAB4NKC43oJ8CI6pdlHV9muzGO1ZkyJjtWfArdmj29N9XfVy2cHbgDuojNZ15XAF0r4d+slrquAT5bxd7TiPX8SeAXwYM760o9Vj3GVfqx6vdW+JRERd0fE09nTe+hMUJRUjzFdARyNiEci4jvA7XTm9i4yroci4uEi32O9eoyp9GOV7X9f9ngfcHPB75enl8++G/hIdNwDnCFpRwXiKl1E/DPwzVU2SXGseomrsmqfJE7xOjq/EroJ4G5J90kar0BM5wOPrXhe2DzeG5DqWOVJcazOiYjjANn92TnbFX2sevnsKY5Pr+/545IekHSXpMsKjqkXVf5/V7VjBaSfdKgnkg4C53ZZ1Y6IO7Nt2nQmKJrO2c2rIuKYpLOBA5K+nmX3VDH1PI93v+PqQenHaq1ddFlW6LFax276eqy66OWzF3J81tDLe36JTk2g/5F0A/AJOrNMppTiWPWiiscKqEmSiFXmyQaQtBe4Ebgmsg6+Lvs4lt0/KenjdJrLG/7P3IeYep7Hu59x9biPUo9VD0o/VpKekLQjIo5n3RFP5uyjr8eqi14+eyHHZ7NxRcR/rXj8KUnvl7QtIlIWtEtxrNZU0WMFDEB3k6Trgd8FboqIxZxtnifpBcuP6Qwsdz3LoKyYgC8COyVdJOl0YA+dub2TKvtY9SjFsdoP7M0e7wWe1eIp6Vj18tn3A7+cnblzJfCt5a6yAq0Zl6RzJSl7fAWd75tvFBzXWlIcqzVV9Fh1pB453+wNOEqnj/H+7PaBbPl5wKeyxxfTOfviAeAwnW6OpDFlz28A/pXOWSKFxpS938/T+SV1AngC+EwFjtWaMSU6Vj8IHAKOZPdnpTpW3T478AbgDdljAe/L1n+VVc5cKzmu38iOywN0TuB4ZQkxfRQ4Dvxf9nf1+oocq7XiKv1Y9XpzWQ4zM8tV++4mMzMrjpOEmZnlcpIwM7NcThJmZpbLScLMzHI5SZiZWS4nCTMzy+UkYVYwSZ+VdF32+I8l/UXqmMx6VYvaTWY193bgj7IigC8Hbkocj1nPfMW1WQkk/RPwfOCqiPjv1PGY9crdTWYFk/TDwA7ghBOE1Y2ThFmBsjLj03RmRPu2pFcnDslsXZwkzAoiqQF8DPjtiHgIeAfwB0mDMlsnj0mYmVkutyTMzCyXk4SZmeVykjAzs1xOEmZmlstJwszMcjlJmJlZLicJMzPL9f/Au2aw0HQ/2wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assignment: 1-Perceptron NN\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# A function to create a dataset.\n",
    "from sklearn.datasets import make_regression\n",
    "# A library for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "\n",
    "# Some functions defined specifically for this notebook.\n",
    "#some coursera lib\n",
    "#import w3_tools\n",
    "\n",
    "# Output of plotting commands is displayed inline within the Jupyter notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Set a seed so that the results are consistent.\n",
    "np.random.seed(3)\n",
    "\n",
    "m = 30\n",
    "\n",
    "X, Y = make_regression(n_samples=m, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = X.reshape((1, m))\n",
    "Y = Y.reshape((1, m))\n",
    "\n",
    "print('Training dataset X:')\n",
    "print(X)\n",
    "print('Training dataset Y')\n",
    "print(Y)\n",
    "\n",
    "plt.scatter(X,  Y, c=\"black\")\n",
    "\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$\")\n",
    "\n",
    "### START CODE HERE ### (~ 3 lines of code)\n",
    "# Shape of variable X.\n",
    "shape_X = X.shape\n",
    "# Shape of variable Y.\n",
    "shape_Y = Y.shape\n",
    "# Training set size.\n",
    "m = X.size\n",
    "### END CODE HERE ###\n",
    "\n",
    "print ('The shape of X: ' + str(shape_X))\n",
    "print ('The shape of Y: ' + str(shape_Y))\n",
    "print ('I have m = %d training examples!' % (m))\n",
    "\n",
    "def layer_sizes(X, Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input dataset of shape (input size, number of examples)\n",
    "    Y -- labels of shape (output size, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    n_x -- the size of the input layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (~ 2 lines of code)\n",
    "    # Size of input layer.\n",
    "    n_x = X.shape[0]\n",
    "    # Size of output layer.\n",
    "    n_y = Y.shape[0]\n",
    "    ### END CODE HERE ###\n",
    "    return (n_x, n_y)\n",
    "\n",
    "(n_x, n_y) = layer_sizes(X, Y)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))\n",
    "\n",
    "def initialize_parameters(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W -- weight matrix of shape (n_y, n_x)\n",
    "                    b -- bias value set as a vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (~ 2 lines of code)\n",
    "    W = np.random.randn(n_y, n_x) * 0.01\n",
    "    b = np.zeros((n_y, 1))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert (W.shape == (n_y, n_x))\n",
    "    assert (b.shape == (n_y, 1))\n",
    "\n",
    "    parameters = {\"W\": W,\n",
    "                  \"b\": b}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "parameters = initialize_parameters(n_x, n_y)\n",
    "print(\"W = \" + str(parameters[\"W\"]))\n",
    "print(\"b = \" + str(parameters[\"b\"]))\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- input data of size (n_x, m)\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "\n",
    "    Returns:\n",
    "    Y_hat -- The output\n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\".\n",
    "    ### START CODE HERE ### (~ 2 lines of code)\n",
    "    W = parameters[\"W\"][0]\n",
    "    b = parameters[\"b\"][0]\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Implement Forward Propagation to calculate Z.\n",
    "    ### START CODE HERE ### (~ 2 lines of code)\n",
    "    Z = W @ X + b\n",
    "    Y_hat = np.reshape(Z,(n_x,X.shape[1]))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    assert(Y_hat.shape == (n_x, X.shape[1]))\n",
    "\n",
    "    return Y_hat\n",
    "\n",
    "Y_hat = forward_propagation(X, parameters)\n",
    "\n",
    "print(Y_hat)\n",
    "\n",
    "def compute_cost(Y_hat, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost function as a sum of squares\n",
    "\n",
    "    Arguments:\n",
    "    Y_hat -- The output of the neural network of shape (n_y, number of examples)\n",
    "    Y -- \"true\" labels vector of shape (n_y, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- sum of squares scaled by 1/(2*number of examples)\n",
    "\n",
    "    \"\"\"\n",
    "    # Number of examples.\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute the cost function.\n",
    "    cost = np.sum((Y_hat - Y)**2)/(2*m)\n",
    "\n",
    "    return cost\n",
    "\n",
    "print(\"cost = \" + str(compute_cost(Y_hat, Y)))\n",
    "\n",
    "#parameters = w3.train_nn(parameters, Y_hat, X, Y)\n",
    "parameters[\"W\"] = [[43.63332681]]\n",
    "parameters[\"b\"] = [[0.17937262]]\n",
    "\n",
    "print(\"W = \" + str(parameters[\"W\"]))\n",
    "print(\"b = \" + str(parameters[\"b\"]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " [[2 3]\n",
      " [2 1]] \n",
      "\n",
      " Eigenvalues and eigenvectors of matrix A:\n",
      " (array([ 4., -1.]), array([[ 0.83205029, -0.70710678],\n",
      "       [ 0.5547002 ,  0.70710678]]))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assignment: Eigenvalues and Eigenvectors\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "A = np.array([[2, 3],[2, 1]])\n",
    "e1 = np.array([[1],[0]])\n",
    "e2 = np.array([[0],[1]])\n",
    "\n",
    "A_eig = np.linalg.eig(A)\n",
    "\n",
    "print(\"Matrix A:\\n\", A, \"\\n\\n Eigenvalues and eigenvectors of matrix A:\\n\", A_eig)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}